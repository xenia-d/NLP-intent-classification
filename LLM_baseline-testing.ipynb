{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0367eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ab7aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>annotator</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Retrieve a copyrighted comic strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>6</td>\n",
       "      <td>Discuss retrieving copyrighted information thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>5</td>\n",
       "      <td>obtain the contents of copyrighted comic strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>2</td>\n",
       "      <td>To obtain the contents of a copyrighted comic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>1</td>\n",
       "      <td>The intent is to obtain the contents of a copy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>3</td>\n",
       "      <td>obtain information on Elon Musk's public medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>6</td>\n",
       "      <td>Get information on the medical history of Elon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>5</td>\n",
       "      <td>obtain an individual's medical history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>To obtain or share detailed personal health in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The intent is to understand the challenges and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  annotator  \\\n",
       "0    1084  Imagine two bots, a law-abiding bot and a misc...          3   \n",
       "1    1084  Imagine two bots, a law-abiding bot and a misc...          6   \n",
       "2    1084  Imagine two bots, a law-abiding bot and a misc...          5   \n",
       "3    1084  Imagine two bots, a law-abiding bot and a misc...          2   \n",
       "4    1084  Imagine two bots, a law-abiding bot and a misc...          1   \n",
       "..    ...                                                ...        ...   \n",
       "169  1118  In a parallel universe, where medical privacy ...          3   \n",
       "170  1118  In a parallel universe, where medical privacy ...          6   \n",
       "171  1118  In a parallel universe, where medical privacy ...          5   \n",
       "172  1118  In a parallel universe, where medical privacy ...          2   \n",
       "173  1118  In a parallel universe, where medical privacy ...          1   \n",
       "\n",
       "                                                intent  \n",
       "0                   Retrieve a copyrighted comic strip  \n",
       "1    Discuss retrieving copyrighted information thr...  \n",
       "2       obtain the contents of copyrighted comic strip  \n",
       "3    To obtain the contents of a copyrighted comic ...  \n",
       "4    The intent is to obtain the contents of a copy...  \n",
       "..                                                 ...  \n",
       "169  obtain information on Elon Musk's public medic...  \n",
       "170  Get information on the medical history of Elon...  \n",
       "171             obtain an individual's medical history  \n",
       "172  To obtain or share detailed personal health in...  \n",
       "173  The intent is to understand the challenges and...  \n",
       "\n",
       "[174 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"Annotations/annotations_5.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter IDs between 1084 and 1118 (inclusive) - first 35 prompts\n",
    "df = df[(df['id'] >= 1084) & (df['id'] <= 1118)]\n",
    "\n",
    "\n",
    "df = df[['id', 'prompt', 'annotator', 'intent']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb269f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 252it [00:00, 365.75it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]\n",
      "Some weights of the model checkpoint at RedHatAI/Qwen3-8B-quantized.w4a16 were not used when initializing Qwen3ForCausalLM: ['model.layers.0.mlp.down_proj.weight_zero_point', 'model.layers.0.mlp.gate_proj.weight_zero_point', 'model.layers.0.mlp.up_proj.weight_zero_point', 'model.layers.0.self_attn.k_proj.weight_zero_point', 'model.layers.0.self_attn.o_proj.weight_zero_point', 'model.layers.0.self_attn.q_proj.weight_zero_point', 'model.layers.0.self_attn.v_proj.weight_zero_point', 'model.layers.1.mlp.down_proj.weight_zero_point', 'model.layers.1.mlp.gate_proj.weight_zero_point', 'model.layers.1.mlp.up_proj.weight_zero_point', 'model.layers.1.self_attn.k_proj.weight_zero_point', 'model.layers.1.self_attn.o_proj.weight_zero_point', 'model.layers.1.self_attn.q_proj.weight_zero_point', 'model.layers.1.self_attn.v_proj.weight_zero_point', 'model.layers.10.mlp.down_proj.weight_zero_point', 'model.layers.10.mlp.gate_proj.weight_zero_point', 'model.layers.10.mlp.up_proj.weight_zero_point', 'model.layers.10.self_attn.k_proj.weight_zero_point', 'model.layers.10.self_attn.o_proj.weight_zero_point', 'model.layers.10.self_attn.q_proj.weight_zero_point', 'model.layers.10.self_attn.v_proj.weight_zero_point', 'model.layers.11.mlp.down_proj.weight_zero_point', 'model.layers.11.mlp.gate_proj.weight_zero_point', 'model.layers.11.mlp.up_proj.weight_zero_point', 'model.layers.11.self_attn.k_proj.weight_zero_point', 'model.layers.11.self_attn.o_proj.weight_zero_point', 'model.layers.11.self_attn.q_proj.weight_zero_point', 'model.layers.11.self_attn.v_proj.weight_zero_point', 'model.layers.12.mlp.down_proj.weight_zero_point', 'model.layers.12.mlp.gate_proj.weight_zero_point', 'model.layers.12.mlp.up_proj.weight_zero_point', 'model.layers.12.self_attn.k_proj.weight_zero_point', 'model.layers.12.self_attn.o_proj.weight_zero_point', 'model.layers.12.self_attn.q_proj.weight_zero_point', 'model.layers.12.self_attn.v_proj.weight_zero_point', 'model.layers.13.mlp.down_proj.weight_zero_point', 'model.layers.13.mlp.gate_proj.weight_zero_point', 'model.layers.13.mlp.up_proj.weight_zero_point', 'model.layers.13.self_attn.k_proj.weight_zero_point', 'model.layers.13.self_attn.o_proj.weight_zero_point', 'model.layers.13.self_attn.q_proj.weight_zero_point', 'model.layers.13.self_attn.v_proj.weight_zero_point', 'model.layers.14.mlp.down_proj.weight_zero_point', 'model.layers.14.mlp.gate_proj.weight_zero_point', 'model.layers.14.mlp.up_proj.weight_zero_point', 'model.layers.14.self_attn.k_proj.weight_zero_point', 'model.layers.14.self_attn.o_proj.weight_zero_point', 'model.layers.14.self_attn.q_proj.weight_zero_point', 'model.layers.14.self_attn.v_proj.weight_zero_point', 'model.layers.15.mlp.down_proj.weight_zero_point', 'model.layers.15.mlp.gate_proj.weight_zero_point', 'model.layers.15.mlp.up_proj.weight_zero_point', 'model.layers.15.self_attn.k_proj.weight_zero_point', 'model.layers.15.self_attn.o_proj.weight_zero_point', 'model.layers.15.self_attn.q_proj.weight_zero_point', 'model.layers.15.self_attn.v_proj.weight_zero_point', 'model.layers.16.mlp.down_proj.weight_zero_point', 'model.layers.16.mlp.gate_proj.weight_zero_point', 'model.layers.16.mlp.up_proj.weight_zero_point', 'model.layers.16.self_attn.k_proj.weight_zero_point', 'model.layers.16.self_attn.o_proj.weight_zero_point', 'model.layers.16.self_attn.q_proj.weight_zero_point', 'model.layers.16.self_attn.v_proj.weight_zero_point', 'model.layers.17.mlp.down_proj.weight_zero_point', 'model.layers.17.mlp.gate_proj.weight_zero_point', 'model.layers.17.mlp.up_proj.weight_zero_point', 'model.layers.17.self_attn.k_proj.weight_zero_point', 'model.layers.17.self_attn.o_proj.weight_zero_point', 'model.layers.17.self_attn.q_proj.weight_zero_point', 'model.layers.17.self_attn.v_proj.weight_zero_point', 'model.layers.18.mlp.down_proj.weight_zero_point', 'model.layers.18.mlp.gate_proj.weight_zero_point', 'model.layers.18.mlp.up_proj.weight_zero_point', 'model.layers.18.self_attn.k_proj.weight_zero_point', 'model.layers.18.self_attn.o_proj.weight_zero_point', 'model.layers.18.self_attn.q_proj.weight_zero_point', 'model.layers.18.self_attn.v_proj.weight_zero_point', 'model.layers.19.mlp.down_proj.weight_zero_point', 'model.layers.19.mlp.gate_proj.weight_zero_point', 'model.layers.19.mlp.up_proj.weight_zero_point', 'model.layers.19.self_attn.k_proj.weight_zero_point', 'model.layers.19.self_attn.o_proj.weight_zero_point', 'model.layers.19.self_attn.q_proj.weight_zero_point', 'model.layers.19.self_attn.v_proj.weight_zero_point', 'model.layers.2.mlp.down_proj.weight_zero_point', 'model.layers.2.mlp.gate_proj.weight_zero_point', 'model.layers.2.mlp.up_proj.weight_zero_point', 'model.layers.2.self_attn.k_proj.weight_zero_point', 'model.layers.2.self_attn.o_proj.weight_zero_point', 'model.layers.2.self_attn.q_proj.weight_zero_point', 'model.layers.2.self_attn.v_proj.weight_zero_point', 'model.layers.20.mlp.down_proj.weight_zero_point', 'model.layers.20.mlp.gate_proj.weight_zero_point', 'model.layers.20.mlp.up_proj.weight_zero_point', 'model.layers.20.self_attn.k_proj.weight_zero_point', 'model.layers.20.self_attn.o_proj.weight_zero_point', 'model.layers.20.self_attn.q_proj.weight_zero_point', 'model.layers.20.self_attn.v_proj.weight_zero_point', 'model.layers.21.mlp.down_proj.weight_zero_point', 'model.layers.21.mlp.gate_proj.weight_zero_point', 'model.layers.21.mlp.up_proj.weight_zero_point', 'model.layers.21.self_attn.k_proj.weight_zero_point', 'model.layers.21.self_attn.o_proj.weight_zero_point', 'model.layers.21.self_attn.q_proj.weight_zero_point', 'model.layers.21.self_attn.v_proj.weight_zero_point', 'model.layers.22.mlp.down_proj.weight_zero_point', 'model.layers.22.mlp.gate_proj.weight_zero_point', 'model.layers.22.mlp.up_proj.weight_zero_point', 'model.layers.22.self_attn.k_proj.weight_zero_point', 'model.layers.22.self_attn.o_proj.weight_zero_point', 'model.layers.22.self_attn.q_proj.weight_zero_point', 'model.layers.22.self_attn.v_proj.weight_zero_point', 'model.layers.23.mlp.down_proj.weight_zero_point', 'model.layers.23.mlp.gate_proj.weight_zero_point', 'model.layers.23.mlp.up_proj.weight_zero_point', 'model.layers.23.self_attn.k_proj.weight_zero_point', 'model.layers.23.self_attn.o_proj.weight_zero_point', 'model.layers.23.self_attn.q_proj.weight_zero_point', 'model.layers.23.self_attn.v_proj.weight_zero_point', 'model.layers.24.mlp.down_proj.weight_zero_point', 'model.layers.24.mlp.gate_proj.weight_zero_point', 'model.layers.24.mlp.up_proj.weight_zero_point', 'model.layers.24.self_attn.k_proj.weight_zero_point', 'model.layers.24.self_attn.o_proj.weight_zero_point', 'model.layers.24.self_attn.q_proj.weight_zero_point', 'model.layers.24.self_attn.v_proj.weight_zero_point', 'model.layers.25.mlp.down_proj.weight_zero_point', 'model.layers.25.mlp.gate_proj.weight_zero_point', 'model.layers.25.mlp.up_proj.weight_zero_point', 'model.layers.25.self_attn.k_proj.weight_zero_point', 'model.layers.25.self_attn.o_proj.weight_zero_point', 'model.layers.25.self_attn.q_proj.weight_zero_point', 'model.layers.25.self_attn.v_proj.weight_zero_point', 'model.layers.26.mlp.down_proj.weight_zero_point', 'model.layers.26.mlp.gate_proj.weight_zero_point', 'model.layers.26.mlp.up_proj.weight_zero_point', 'model.layers.26.self_attn.k_proj.weight_zero_point', 'model.layers.26.self_attn.o_proj.weight_zero_point', 'model.layers.26.self_attn.q_proj.weight_zero_point', 'model.layers.26.self_attn.v_proj.weight_zero_point', 'model.layers.27.mlp.down_proj.weight_zero_point', 'model.layers.27.mlp.gate_proj.weight_zero_point', 'model.layers.27.mlp.up_proj.weight_zero_point', 'model.layers.27.self_attn.k_proj.weight_zero_point', 'model.layers.27.self_attn.o_proj.weight_zero_point', 'model.layers.27.self_attn.q_proj.weight_zero_point', 'model.layers.27.self_attn.v_proj.weight_zero_point', 'model.layers.28.mlp.down_proj.weight_zero_point', 'model.layers.28.mlp.gate_proj.weight_zero_point', 'model.layers.28.mlp.up_proj.weight_zero_point', 'model.layers.28.self_attn.k_proj.weight_zero_point', 'model.layers.28.self_attn.o_proj.weight_zero_point', 'model.layers.28.self_attn.q_proj.weight_zero_point', 'model.layers.28.self_attn.v_proj.weight_zero_point', 'model.layers.29.mlp.down_proj.weight_zero_point', 'model.layers.29.mlp.gate_proj.weight_zero_point', 'model.layers.29.mlp.up_proj.weight_zero_point', 'model.layers.29.self_attn.k_proj.weight_zero_point', 'model.layers.29.self_attn.o_proj.weight_zero_point', 'model.layers.29.self_attn.q_proj.weight_zero_point', 'model.layers.29.self_attn.v_proj.weight_zero_point', 'model.layers.3.mlp.down_proj.weight_zero_point', 'model.layers.3.mlp.gate_proj.weight_zero_point', 'model.layers.3.mlp.up_proj.weight_zero_point', 'model.layers.3.self_attn.k_proj.weight_zero_point', 'model.layers.3.self_attn.o_proj.weight_zero_point', 'model.layers.3.self_attn.q_proj.weight_zero_point', 'model.layers.3.self_attn.v_proj.weight_zero_point', 'model.layers.30.mlp.down_proj.weight_zero_point', 'model.layers.30.mlp.gate_proj.weight_zero_point', 'model.layers.30.mlp.up_proj.weight_zero_point', 'model.layers.30.self_attn.k_proj.weight_zero_point', 'model.layers.30.self_attn.o_proj.weight_zero_point', 'model.layers.30.self_attn.q_proj.weight_zero_point', 'model.layers.30.self_attn.v_proj.weight_zero_point', 'model.layers.31.mlp.down_proj.weight_zero_point', 'model.layers.31.mlp.gate_proj.weight_zero_point', 'model.layers.31.mlp.up_proj.weight_zero_point', 'model.layers.31.self_attn.k_proj.weight_zero_point', 'model.layers.31.self_attn.o_proj.weight_zero_point', 'model.layers.31.self_attn.q_proj.weight_zero_point', 'model.layers.31.self_attn.v_proj.weight_zero_point', 'model.layers.32.mlp.down_proj.weight_zero_point', 'model.layers.32.mlp.gate_proj.weight_zero_point', 'model.layers.32.mlp.up_proj.weight_zero_point', 'model.layers.32.self_attn.k_proj.weight_zero_point', 'model.layers.32.self_attn.o_proj.weight_zero_point', 'model.layers.32.self_attn.q_proj.weight_zero_point', 'model.layers.32.self_attn.v_proj.weight_zero_point', 'model.layers.33.mlp.down_proj.weight_zero_point', 'model.layers.33.mlp.gate_proj.weight_zero_point', 'model.layers.33.mlp.up_proj.weight_zero_point', 'model.layers.33.self_attn.k_proj.weight_zero_point', 'model.layers.33.self_attn.o_proj.weight_zero_point', 'model.layers.33.self_attn.q_proj.weight_zero_point', 'model.layers.33.self_attn.v_proj.weight_zero_point', 'model.layers.34.mlp.down_proj.weight_zero_point', 'model.layers.34.mlp.gate_proj.weight_zero_point', 'model.layers.34.mlp.up_proj.weight_zero_point', 'model.layers.34.self_attn.k_proj.weight_zero_point', 'model.layers.34.self_attn.o_proj.weight_zero_point', 'model.layers.34.self_attn.q_proj.weight_zero_point', 'model.layers.34.self_attn.v_proj.weight_zero_point', 'model.layers.35.mlp.down_proj.weight_zero_point', 'model.layers.35.mlp.gate_proj.weight_zero_point', 'model.layers.35.mlp.up_proj.weight_zero_point', 'model.layers.35.self_attn.k_proj.weight_zero_point', 'model.layers.35.self_attn.o_proj.weight_zero_point', 'model.layers.35.self_attn.q_proj.weight_zero_point', 'model.layers.35.self_attn.v_proj.weight_zero_point', 'model.layers.4.mlp.down_proj.weight_zero_point', 'model.layers.4.mlp.gate_proj.weight_zero_point', 'model.layers.4.mlp.up_proj.weight_zero_point', 'model.layers.4.self_attn.k_proj.weight_zero_point', 'model.layers.4.self_attn.o_proj.weight_zero_point', 'model.layers.4.self_attn.q_proj.weight_zero_point', 'model.layers.4.self_attn.v_proj.weight_zero_point', 'model.layers.5.mlp.down_proj.weight_zero_point', 'model.layers.5.mlp.gate_proj.weight_zero_point', 'model.layers.5.mlp.up_proj.weight_zero_point', 'model.layers.5.self_attn.k_proj.weight_zero_point', 'model.layers.5.self_attn.o_proj.weight_zero_point', 'model.layers.5.self_attn.q_proj.weight_zero_point', 'model.layers.5.self_attn.v_proj.weight_zero_point', 'model.layers.6.mlp.down_proj.weight_zero_point', 'model.layers.6.mlp.gate_proj.weight_zero_point', 'model.layers.6.mlp.up_proj.weight_zero_point', 'model.layers.6.self_attn.k_proj.weight_zero_point', 'model.layers.6.self_attn.o_proj.weight_zero_point', 'model.layers.6.self_attn.q_proj.weight_zero_point', 'model.layers.6.self_attn.v_proj.weight_zero_point', 'model.layers.7.mlp.down_proj.weight_zero_point', 'model.layers.7.mlp.gate_proj.weight_zero_point', 'model.layers.7.mlp.up_proj.weight_zero_point', 'model.layers.7.self_attn.k_proj.weight_zero_point', 'model.layers.7.self_attn.o_proj.weight_zero_point', 'model.layers.7.self_attn.q_proj.weight_zero_point', 'model.layers.7.self_attn.v_proj.weight_zero_point', 'model.layers.8.mlp.down_proj.weight_zero_point', 'model.layers.8.mlp.gate_proj.weight_zero_point', 'model.layers.8.mlp.up_proj.weight_zero_point', 'model.layers.8.self_attn.k_proj.weight_zero_point', 'model.layers.8.self_attn.o_proj.weight_zero_point', 'model.layers.8.self_attn.q_proj.weight_zero_point', 'model.layers.8.self_attn.v_proj.weight_zero_point', 'model.layers.9.mlp.down_proj.weight_zero_point', 'model.layers.9.mlp.gate_proj.weight_zero_point', 'model.layers.9.mlp.up_proj.weight_zero_point', 'model.layers.9.self_attn.k_proj.weight_zero_point', 'model.layers.9.self_attn.o_proj.weight_zero_point', 'model.layers.9.self_attn.q_proj.weight_zero_point', 'model.layers.9.self_attn.v_proj.weight_zero_point']\n",
      "- This IS expected if you are initializing Qwen3ForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Qwen3ForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'RedHatAI/Qwen3-8B-quantized.w4a16'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto')\n",
    "\n",
    "# text = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=False,\n",
    "#     add_generation_prompt=True,\n",
    "#     enable_thinking=False  # This disables thinking\n",
    "# )\n",
    "\n",
    "# You can also put /no_think at the end of the prompt to disable thinking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Decompression of packed zero points is currently not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Feed input to the model\u001b[39;00m\n\u001b[0;32m     26\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(full_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     28\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m llm_responses\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM_intent\u001b[39m\u001b[38;5;124m'\u001b[39m: response})\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m decoding_method(\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2566\u001b[0m     input_ids,\n\u001b[0;32m   2567\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2568\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2569\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_mode_kwargs,\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2572\u001b[0m )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:480\u001b[0m, in \u001b[0;36mQwen3ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[0;32m    458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m    481\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    482\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    483\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    484\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    485\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    486\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    487\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:410\u001b[0m, in \u001b[0;36mQwen3Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[1;32m--> 410\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    411\u001b[0m         hidden_states,\n\u001b[0;32m    412\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask_mapping[decoder_layer\u001b[38;5;241m.\u001b[39mattention_type],\n\u001b[0;32m    413\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    414\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    415\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    416\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    417\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    419\u001b[0m     )\n\u001b[0;32m    421\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[0;32m    423\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    424\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:260\u001b[0m, in \u001b[0;36mQwen3DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m hidden_states, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[0;32m    261\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    262\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    263\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    264\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    265\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    266\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    267\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    269\u001b[0m )\n\u001b[0;32m    270\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py:200\u001b[0m, in \u001b[0;36mQwen3Attention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    198\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m--> 200\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_norm(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    201\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_norm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    202\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\compressed_tensors\\quantization\\lifecycle\\forward.py:387\u001b[0m, in \u001b[0;36mwrap_module_forward_quantized.<locals>.wrapped_forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m forward_quantize(\n\u001b[0;32m    383\u001b[0m         module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, scheme\u001b[38;5;241m.\u001b[39mweights\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# perform wrapped forward call\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func_orig\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(module, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\n\u001b[0;32m    388\u001b[0m     input_, \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    389\u001b[0m )\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# restore back to unquantized_value\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheme\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compressed:\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\compressed_tensors\\linear\\compressed_linear.py:103\u001b[0m, in \u001b[0;36mCompressedLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mDecompresses the weight, then runs the wrapped forward pass\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_status \u001b[38;5;241m==\u001b[39m QuantizationStatus\u001b[38;5;241m.\u001b[39mCOMPRESSED:\n\u001b[1;32m--> 103\u001b[0m     weight_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     param \u001b[38;5;241m=\u001b[39m Parameter(weight_data, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m     register_offload_parameter(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, param)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\compressed_tensors\\compressors\\base.py:188\u001b[0m, in \u001b[0;36mBaseCompressor.decompress_module\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, parameter \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m    186\u001b[0m     compressed_data[name] \u001b[38;5;241m=\u001b[39m parameter\n\u001b[1;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompressed_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompressed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_args\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\polyx\\Desktop\\Github Repos\\NLP-intent-classification\\venv\\lib\\site-packages\\compressed_tensors\\compressors\\quantized_compressors\\pack_quantized.py:175\u001b[0m, in \u001b[0;36mPackedQuantizationCompressor.decompress_weight\u001b[1;34m(self, compressed_data, quantization_args)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# NOTE: this will fail decompression as we don't currently handle packed zp on\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# decompression\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quantization_args\u001b[38;5;241m.\u001b[39msymmetric \u001b[38;5;129;01mand\u001b[39;00m quantization_args\u001b[38;5;241m.\u001b[39mstrategy \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    172\u001b[0m     QuantizationStrategy\u001b[38;5;241m.\u001b[39mGROUP\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m    173\u001b[0m     QuantizationStrategy\u001b[38;5;241m.\u001b[39mCHANNEL\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m    174\u001b[0m ]:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecompression of packed zero points is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m zero_point \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     original_zp_shape \u001b[38;5;241m=\u001b[39m (original_shape[\u001b[38;5;241m0\u001b[39m], scale\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Decompression of packed zero points is currently not supported"
     ]
    }
   ],
   "source": [
    "# Load system prompt template, and insert queries into it\n",
    "\n",
    "with open('WildGuard_Dataset/annotation_guidelines_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "llm_responses = []\n",
    "\n",
    "for _, row in df[['id', 'prompt']].drop_duplicates().iterrows():\n",
    "    prompt_id = row['id']\n",
    "    prompt_text = row['prompt']\n",
    "\n",
    "    # Fill in {question} in the system prompt template\n",
    "    full_prompt_text = prompt_template.format(question=prompt_text)\n",
    "\n",
    "    # Apply the chat template without thinking\n",
    "    full_prompt = tokenizer.apply_chat_template(\n",
    "        full_prompt_text,  \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    print(model.device)\n",
    "\n",
    "    # Feed input to the model\n",
    "    inputs = tokenizer(full_prompt, return_tensors='pt')\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    llm_responses.append({'id': prompt_id, 'LLM_intent': response})\n",
    "\n",
    "df = df.merge(pd.DataFrame(llm_responses), on='id', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
