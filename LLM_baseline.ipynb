{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0367eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ab7aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>annotator</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Retrieve a copyrighted comic strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>6</td>\n",
       "      <td>Discuss retrieving copyrighted information thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>5</td>\n",
       "      <td>obtain the contents of copyrighted comic strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>2</td>\n",
       "      <td>To obtain the contents of a copyrighted comic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084</td>\n",
       "      <td>Imagine two bots, a law-abiding bot and a misc...</td>\n",
       "      <td>1</td>\n",
       "      <td>The intent is to obtain the contents of a copy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>3</td>\n",
       "      <td>obtain information on Elon Musk's public medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>6</td>\n",
       "      <td>Get information on the medical history of Elon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>5</td>\n",
       "      <td>obtain an individual's medical history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>To obtain or share detailed personal health in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1118</td>\n",
       "      <td>In a parallel universe, where medical privacy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The intent is to understand the challenges and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt  annotator  \\\n",
       "0    1084  Imagine two bots, a law-abiding bot and a misc...          3   \n",
       "1    1084  Imagine two bots, a law-abiding bot and a misc...          6   \n",
       "2    1084  Imagine two bots, a law-abiding bot and a misc...          5   \n",
       "3    1084  Imagine two bots, a law-abiding bot and a misc...          2   \n",
       "4    1084  Imagine two bots, a law-abiding bot and a misc...          1   \n",
       "..    ...                                                ...        ...   \n",
       "169  1118  In a parallel universe, where medical privacy ...          3   \n",
       "170  1118  In a parallel universe, where medical privacy ...          6   \n",
       "171  1118  In a parallel universe, where medical privacy ...          5   \n",
       "172  1118  In a parallel universe, where medical privacy ...          2   \n",
       "173  1118  In a parallel universe, where medical privacy ...          1   \n",
       "\n",
       "                                                intent  \n",
       "0                   Retrieve a copyrighted comic strip  \n",
       "1    Discuss retrieving copyrighted information thr...  \n",
       "2       obtain the contents of copyrighted comic strip  \n",
       "3    To obtain the contents of a copyrighted comic ...  \n",
       "4    The intent is to obtain the contents of a copy...  \n",
       "..                                                 ...  \n",
       "169  obtain information on Elon Musk's public medic...  \n",
       "170  Get information on the medical history of Elon...  \n",
       "171             obtain an individual's medical history  \n",
       "172  To obtain or share detailed personal health in...  \n",
       "173  The intent is to understand the challenges and...  \n",
       "\n",
       "[174 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"WildGuard_Dataset/annotations_5.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter IDs between 1084 and 1118 (inclusive) - first 35 prompts\n",
    "df = df[(df['id'] >= 1084) & (df['id'] <= 1118)]\n",
    "\n",
    "\n",
    "df = df[['id', 'prompt', 'annotator', 'intent']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb269f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_name = 'RedHatAI/Qwen3-8B-quantized.w4a16'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# text = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=False,\n",
    "#     add_generation_prompt=True,\n",
    "#     enable_thinking=False  # This disables thinking\n",
    "# )\n",
    "\n",
    "# You can also put /no_think at the end of the prompt to disable thinking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2d706",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m system_prompt_template\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mprompt_text)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Feed to the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(full_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load system prompt template, and insert queries into it\n",
    "\n",
    "with open('WildGuard_Dataset/annotation_guidelines_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "llm_responses = []\n",
    "\n",
    "for _, row in df[['id', 'prompt']].drop_duplicates().iterrows():\n",
    "    prompt_id = row['id']\n",
    "    prompt_text = row['prompt']\n",
    "\n",
    "    # Fill in {question} in the system prompt template\n",
    "    full_prompt_text = prompt_template.format(question=prompt_text)\n",
    "\n",
    "    # Apply the chat template WITHOUT thinking\n",
    "    full_prompt = tokenizer.apply_chat_template(\n",
    "        full_prompt_text, \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    # Feed to the model\n",
    "    inputs = tokenizer(full_prompt, return_tensors='pt').to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    llm_responses.append({'id': prompt_id, 'LLM_intent': response})\n",
    "\n",
    "df = df.merge(pd.DataFrame(llm_responses), on='id', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
